{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card fraud classifier\n",
    "\n",
    "Classifying anonymized credit card fraud transactions dataset from kaggle: https://www.kaggle.com/dalpozz/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can tweak these settings as you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "batch_size = 10\n",
    "state_size = 64\n",
    "num_features = 30\n",
    "num_classes = 1\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 50              #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from csv and get train and test data length:\n",
    "dataset is already balanced, so no need to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file_path = \"data/creditcard_sampled.csv\"\n",
    "\n",
    "dataset = pd.read_csv(csv_file_path)\n",
    "train_length = int(len(dataset.index) * train_size)\n",
    "test_length = int(len(dataset.index) * (1.0 - train_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used features from csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "            \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\n",
    "            \"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\n",
    "            \"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\n",
    "            \"V28\",\"Amount\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize dataset and split train/test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_norm = (dataset - dataset.min()) / (dataset.max() - dataset.min())\n",
    "dataset_norm = dataset_norm.sample(frac=1)\n",
    "dataset_train = dataset_norm[dataset.index < train_length]\n",
    "dataset_test = dataset_norm[dataset.index >= train_length]\n",
    "\n",
    "x_train = dataset_train[features].as_matrix()\n",
    "y_train = dataset_train[[\"Class\"]].as_matrix()\n",
    "x_test = dataset_test[features].as_matrix()\n",
    "y_test = dataset_test[[\"Class\"]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:-(len(x_train) % num_features)].reshape([-1, num_features])\n",
    "y_train = y_train[:-(len(y_train) % num_features)].reshape([-1, num_classes])\n",
    "x_test = x_test[:-(len(x_test) % num_features)].reshape([-1, num_features])\n",
    "y_test = y_test[:-(len(y_test) % num_features)].reshape([-1, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and compile model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(state_size, input_dim=num_features, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(state_size, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "780/780 [==============================] - 0s - loss: 0.6441 - acc: 0.6397     \n",
      "Epoch 2/50\n",
      "780/780 [==============================] - 0s - loss: 0.5452 - acc: 0.7795     \n",
      "Epoch 3/50\n",
      "780/780 [==============================] - 0s - loss: 0.4303 - acc: 0.8359     \n",
      "Epoch 4/50\n",
      "780/780 [==============================] - 0s - loss: 0.3493 - acc: 0.8615     \n",
      "Epoch 5/50\n",
      "780/780 [==============================] - 0s - loss: 0.3006 - acc: 0.8987     \n",
      "Epoch 6/50\n",
      "780/780 [==============================] - 0s - loss: 0.2568 - acc: 0.9103     \n",
      "Epoch 7/50\n",
      "780/780 [==============================] - 0s - loss: 0.2310 - acc: 0.9231     \n",
      "Epoch 8/50\n",
      "780/780 [==============================] - 0s - loss: 0.2168 - acc: 0.9359     \n",
      "Epoch 9/50\n",
      "780/780 [==============================] - 0s - loss: 0.2175 - acc: 0.9372     \n",
      "Epoch 10/50\n",
      "780/780 [==============================] - 0s - loss: 0.1858 - acc: 0.9410     \n",
      "Epoch 11/50\n",
      "780/780 [==============================] - 0s - loss: 0.1964 - acc: 0.9346     \n",
      "Epoch 12/50\n",
      "780/780 [==============================] - 0s - loss: 0.1764 - acc: 0.9474     \n",
      "Epoch 13/50\n",
      "780/780 [==============================] - 0s - loss: 0.1789 - acc: 0.9410     \n",
      "Epoch 14/50\n",
      "780/780 [==============================] - 0s - loss: 0.1580 - acc: 0.9487     \n",
      "Epoch 15/50\n",
      "780/780 [==============================] - 0s - loss: 0.1668 - acc: 0.9577     \n",
      "Epoch 16/50\n",
      "780/780 [==============================] - 0s - loss: 0.1520 - acc: 0.9564     \n",
      "Epoch 17/50\n",
      "780/780 [==============================] - 0s - loss: 0.1557 - acc: 0.9538     \n",
      "Epoch 18/50\n",
      "780/780 [==============================] - 0s - loss: 0.1472 - acc: 0.9551     \n",
      "Epoch 19/50\n",
      "780/780 [==============================] - 0s - loss: 0.1449 - acc: 0.9500     \n",
      "Epoch 20/50\n",
      "780/780 [==============================] - 0s - loss: 0.1399 - acc: 0.9564     \n",
      "Epoch 21/50\n",
      "780/780 [==============================] - 0s - loss: 0.1491 - acc: 0.9577     \n",
      "Epoch 22/50\n",
      "780/780 [==============================] - 0s - loss: 0.1350 - acc: 0.9615     \n",
      "Epoch 23/50\n",
      "780/780 [==============================] - 0s - loss: 0.1320 - acc: 0.9615     \n",
      "Epoch 24/50\n",
      "780/780 [==============================] - 0s - loss: 0.1337 - acc: 0.9615     \n",
      "Epoch 25/50\n",
      "780/780 [==============================] - 0s - loss: 0.1337 - acc: 0.9679     \n",
      "Epoch 26/50\n",
      "780/780 [==============================] - 0s - loss: 0.1368 - acc: 0.9564     \n",
      "Epoch 27/50\n",
      "780/780 [==============================] - 0s - loss: 0.1333 - acc: 0.9615     \n",
      "Epoch 28/50\n",
      "780/780 [==============================] - 0s - loss: 0.1077 - acc: 0.9718     \n",
      "Epoch 29/50\n",
      "780/780 [==============================] - 0s - loss: 0.1328 - acc: 0.9577     \n",
      "Epoch 30/50\n",
      "780/780 [==============================] - 0s - loss: 0.1266 - acc: 0.9538     \n",
      "Epoch 31/50\n",
      "780/780 [==============================] - 0s - loss: 0.1086 - acc: 0.9603     \n",
      "Epoch 32/50\n",
      "780/780 [==============================] - 0s - loss: 0.1123 - acc: 0.9667     \n",
      "Epoch 33/50\n",
      "780/780 [==============================] - 0s - loss: 0.1196 - acc: 0.9628     \n",
      "Epoch 34/50\n",
      "780/780 [==============================] - 0s - loss: 0.1252 - acc: 0.9654     \n",
      "Epoch 35/50\n",
      "780/780 [==============================] - 0s - loss: 0.1170 - acc: 0.9667     \n",
      "Epoch 36/50\n",
      "780/780 [==============================] - 0s - loss: 0.1323 - acc: 0.9641     \n",
      "Epoch 37/50\n",
      "780/780 [==============================] - 0s - loss: 0.1171 - acc: 0.9705     \n",
      "Epoch 38/50\n",
      "780/780 [==============================] - 0s - loss: 0.1296 - acc: 0.9641     \n",
      "Epoch 39/50\n",
      "780/780 [==============================] - 0s - loss: 0.1144 - acc: 0.9705     \n",
      "Epoch 40/50\n",
      "780/780 [==============================] - 0s - loss: 0.1153 - acc: 0.9667     \n",
      "Epoch 41/50\n",
      "780/780 [==============================] - 0s - loss: 0.1227 - acc: 0.9615     \n",
      "Epoch 42/50\n",
      "780/780 [==============================] - 0s - loss: 0.1100 - acc: 0.9679     \n",
      "Epoch 43/50\n",
      "780/780 [==============================] - 0s - loss: 0.1193 - acc: 0.9692     \n",
      "Epoch 44/50\n",
      "780/780 [==============================] - 0s - loss: 0.1190 - acc: 0.9641     \n",
      "Epoch 45/50\n",
      "780/780 [==============================] - 0s - loss: 0.1226 - acc: 0.9628     \n",
      "Epoch 46/50\n",
      "780/780 [==============================] - 0s - loss: 0.1029 - acc: 0.9705     \n",
      "Epoch 47/50\n",
      "780/780 [==============================] - 0s - loss: 0.1090 - acc: 0.9731     \n",
      "Epoch 48/50\n",
      "780/780 [==============================] - 0s - loss: 0.1183 - acc: 0.9667     \n",
      "Epoch 49/50\n",
      "780/780 [==============================] - 0s - loss: 0.1087 - acc: 0.9667     \n",
      "Epoch 50/50\n",
      "780/780 [==============================] - 0s - loss: 0.1049 - acc: 0.9705     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c9bf58668>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/180 [>.............................] - ETA: 1s\n",
      "Accuracy: 96.67 % \n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nAccuracy: {0:.2f} % \".format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c9bf6ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = list(map(lambda x: int(round(x[0])), model.predict(x_test)))\n",
    "x = [0] * preds.count(0)\n",
    "y = [1] * preds.count(1)\n",
    "\n",
    "bins = np.linspace(-2, 2, 10)\n",
    "plt.hist(x, bins, alpha=1, label='predicted: 0')\n",
    "plt.hist(y, bins, alpha=1, label='predicted: 1')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
